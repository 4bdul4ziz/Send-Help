{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Based on the Grow Tree and BestSplit-Class algorithms and using the entropy impurity function, create a decision tree to learn the GoodMovie concept. Show how each node is\n",
    "decided (based on comparing impurity measures), then draw the full decision tree. If there are ties in impurity measures, give higher priority to attributes and values according to their order on page 1: that is, Budget is the highest priority feature and Director is the lowest priority; within Budget, Low is the highest priority value, followed\n",
    "by Medium and then High. [Normally these might be randomly chosen, but we'll use this\n",
    "\"inductive bias.\"] If there are ties to determine a leaf's label, give priority to \"Yes.\" Now apply this learned concept (decision tree) to the three test data sets posted on the Assignments page, and list the correctly and incorrectly classified examples (by number),\n",
    "for each test data set.\n",
    "What is the error rate of the decision tree on the training data? On each test data set?\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from IPython.display import Image\n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 1 elements, new values have 5 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Read training.txt\u001b[39;00m\n\u001b[1;32m      2\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mtraining.txt\u001b[39m\u001b[39m\"\u001b[39m, sep\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m, header\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m df\u001b[39m.\u001b[39;49mcolumns \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mBudget\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mGenre\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mFamousActors\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDirectors\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mGoodMovie\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      4\u001b[0m df\n\u001b[1;32m      6\u001b[0m \u001b[39m# Calculate the entropy of the GoodMovie column\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/generic.py:5920\u001b[0m, in \u001b[0;36mNDFrame.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5918\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   5919\u001b[0m     \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__getattribute__\u001b[39m(\u001b[39mself\u001b[39m, name)\n\u001b[0;32m-> 5920\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__setattr__\u001b[39;49m(\u001b[39mself\u001b[39;49m, name, value)\n\u001b[1;32m   5921\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[1;32m   5922\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/_libs/properties.pyx:69\u001b[0m, in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/generic.py:822\u001b[0m, in \u001b[0;36mNDFrame._set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    820\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_axis\u001b[39m(\u001b[39mself\u001b[39m, axis: \u001b[39mint\u001b[39m, labels: AnyArrayLike \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    821\u001b[0m     labels \u001b[39m=\u001b[39m ensure_index(labels)\n\u001b[0;32m--> 822\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mset_axis(axis, labels)\n\u001b[1;32m    823\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/internals/managers.py:228\u001b[0m, in \u001b[0;36mBaseBlockManager.set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_axis\u001b[39m(\u001b[39mself\u001b[39m, axis: \u001b[39mint\u001b[39m, new_labels: Index) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[39m# Caller is responsible for ensuring we have an Index object.\u001b[39;00m\n\u001b[0;32m--> 228\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_set_axis(axis, new_labels)\n\u001b[1;32m    229\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis] \u001b[39m=\u001b[39m new_labels\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pandas/core/internals/base.py:70\u001b[0m, in \u001b[0;36mDataManager._validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39melif\u001b[39;00m new_len \u001b[39m!=\u001b[39m old_len:\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     71\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLength mismatch: Expected axis has \u001b[39m\u001b[39m{\u001b[39;00mold_len\u001b[39m}\u001b[39;00m\u001b[39m elements, new \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalues have \u001b[39m\u001b[39m{\u001b[39;00mnew_len\u001b[39m}\u001b[39;00m\u001b[39m elements\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 1 elements, new values have 5 elements"
     ]
    }
   ],
   "source": [
    "# Read training.txt\n",
    "df = pd.read_csv(\"training.txt\", sep=\"\\t\", header=None)\n",
    "df.columns = [\"Budget\", \"Genre\", \"FamousActors\", \"Directors\", \"GoodMovie\"]\n",
    "df\n",
    "\n",
    "# Calculate the entropy of the GoodMovie column\n",
    "def entropy(col):\n",
    "    elements, counts = np.unique(col, return_counts=True)\n",
    "    entropy = np.sum([(-counts[i]/np.sum(counts)) * math.log(counts[i]/np.sum(counts), 2) for i in range(len(elements))])\n",
    "    return entropy\n",
    "\n",
    "# Calculate the information gain\n",
    "def InfoGain(data, split_attribute_name, target_name=\"GoodMovie\"):\n",
    "    # Calculate the entropy of the total dataset\n",
    "    total_entropy = entropy(data[target_name])\n",
    "    \n",
    "    # Calculate the values and the corresponding counts for the split attribute \n",
    "    vals, counts= np.unique(data[split_attribute_name], return_counts=True)\n",
    "    \n",
    "    # Calculate the weighted entropy\n",
    "    Weighted_Entropy = np.sum([(counts[i]/np.sum(counts)) * entropy(data.where(data[split_attribute_name]==vals[i]).dropna()[target_name]) for i in range(len(vals))])\n",
    "    \n",
    "    # Calculate the information gain\n",
    "    Information_Gain = total_entropy - Weighted_Entropy\n",
    "    return Information_Gain\n",
    "\n",
    "# Find the best attribute to split on\n",
    "def BestSplit(data, attributes, target_name=\"GoodMovie\"):\n",
    "    # Calculate the information gain for each attribute\n",
    "    gains = [InfoGain(data, attr, target_name) for attr in attributes]\n",
    "    # Return the attribute with the highest information gain\n",
    "    return attributes[np.argmax(gains)]\n",
    "\n",
    "# Create a new node\n",
    "def CreateNode(data, attributes, node_type, label=None):\n",
    "    # Create and return a tree node\n",
    "    return {\"data\": data, \"attributes\": attributes, \"node_type\": node_type, \"label\": label}\n",
    "\n",
    "# Create a leaf node\n",
    "def CreateLeaf(label):\n",
    "    # Create and return a leaf node\n",
    "    return {\"node_type\": \"leaf\", \"label\": label}\n",
    "\n",
    "# Grow the tree\n",
    "def GrowTree(node, max_depth, current_depth=0):\n",
    "    # Splitting criteria\n",
    "    # 1. All the tuples belong to the same classification\n",
    "    # 2. There are no more remaining attributes\n",
    "    # 3. Maximum tree depth has been reached\n",
    "    if len(np.unique(node[\"data\"][\"GoodMovie\"])) <= 1 or len(node[\"attributes\"]) ==0 or current_depth == max_depth:\n",
    "        # Create a leaf node\n",
    "        leaf_label = np.unique(node[\"data\"][\"GoodMovie\"])[0]\n",
    "        return CreateLeaf(leaf_label)\n",
    "    \n",
    "    # Find the best attribute to split on\n",
    "    best_attribute = BestSplit(node[\"data\"], node[\"attributes\"])\n",
    "    \n",
    "    # Create a new internal node\n",
    "    new_node = CreateNode(node[\"data\"], node[\"attributes\"], node_type=\"internal\", label=best_attribute)\n",
    "    \n",
    "    # Remove the best attribute from the attribute list\n",
    "    new_node[\"attributes\"].remove(best_attribute)\n",
    "    \n",
    "    # Create a new decision tree/sub-tree for each of the values in the best attribute field\n",
    "    for value in np.unique(node[\"data\"][best_attribute]):\n",
    "        # Split the dataset along the value of the best attribute\n",
    "        sub_data = node[\"data\"].where(node[\"data\"][best_attribute] == value).dropna()\n",
    "        \n",
    "        # Add the new decision tree/sub-tree to the empty dictionary\n",
    "        new_node[value] = GrowTree(CreateNode(sub_data, new_node[\"attributes\"], node_type=\"internal\"), max_depth, current_depth+1)\n",
    "    \n",
    "    return new_node\n",
    "\n",
    "# Print the tree\n",
    "def PrintTree(node, spacing=\"\"):\n",
    "    # Base case: we've reached a leaf\n",
    "    if node[\"node_type\"] == \"leaf\":\n",
    "        print (spacing + \"Predict\", node[\"label\"])\n",
    "        return\n",
    "    \n",
    "    # Print the attribute at this node\n",
    "    print (spacing + node[\"label\"])\n",
    "    \n",
    "    # Print each subtree\n",
    "    for value in node.keys():\n",
    "        if value not in [\"data\", \"attributes\", \"node_type\", \"label\"]:\n",
    "            print (spacing + '--> ' + value + ':')\n",
    "            PrintTree(node[value], spacing + \"  \")\n",
    "\n",
    "# Classify a new instance\n",
    "def Classify(instance, tree):\n",
    "    # Base case: we've reached a leaf\n",
    "    if tree[\"node_type\"] == \"leaf\":\n",
    "        return tree[\"label\"]\n",
    "    \n",
    "    # Decide whether to follow the true-branch or the false-branch\n",
    "    attribute_value = instance[tree[\"label\"]]\n",
    "    \n",
    "    # Check if the attribute value is unknown\n",
    "    if attribute_value not in tree.keys():\n",
    "        return \"Yes\"\n",
    "    \n",
    "    # Follow the branch corresponding to the attribute value\n",
    "    # Return the label of the leaf node\n",
    "    subtree = tree[attribute_value]\n",
    "    return Classify(instance, subtree)\n",
    "\n",
    "# Classify the training set\n",
    "def ClassifyAll(training_set, tree):\n",
    "    # Classify each instance in the training set\n",
    "    prediction = training_set.apply(Classify, args=(tree,), axis=1)\n",
    "    \n",
    "    # Compute the accuracy\n",
    "    accuracy = np.sum(prediction == training_set[\"GoodMovie\"]) / len(training_set[\"GoodMovie\"])\n",
    "    return accuracy\n",
    "\n",
    "# Plot the tree\n",
    "def PlotTree(tree, feature_names):\n",
    "    # Create DOT data\n",
    "    dot_data = export_graphviz(tree, out_file=None, feature_names=feature_names, class_names=[\"No\", \"Yes\"], filled=True, rounded=True, special_characters=True)\n",
    "    \n",
    "    # Draw graph\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "    \n",
    "    # Show graph\n",
    "    Image(graph.create_png())\n",
    "\n",
    "# Create a new tree\n",
    "tree = GrowTree(CreateNode(df, df.columns[:-1], node_type=\"internal\"), max_depth=3)\n",
    "\n",
    "# Print the tree\n",
    "PrintTree(tree)\n",
    "\n",
    "# Plot the tree\n",
    "PlotTree(tree, df.columns[:-1])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
